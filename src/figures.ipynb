{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T17:30:02.027188Z",
     "start_time": "2025-01-19T17:29:59.408942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandak/miniconda3/envs/ecg/lib/python3.8/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import lightning as L\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, roc_curve\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import hydra\n",
    "import wandb\n",
    "from dataset import SupervisedDataset\n",
    "from lightning_modules import SupervisedTask\n",
    "from models.ecg_models import *\n",
    "from run import interpolate\n",
    "pl.Config.set_tbl_rows(50)\n",
    "MY_NAVY = '#001F54'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_RUN='payalchandak/SILVER/nuzrc47q'\n",
    "COHORTS = ['all','worsen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "for site in [\n",
    "    {\n",
    "        'name':'MGH',\n",
    "        'split':'train',\n",
    "        'line':'-',\n",
    "    },\n",
    "]:\n",
    "    device = 'cuda:1'\n",
    "    cfg = OmegaConf.create(wandb.Api().run(WANDB_RUN).config)\n",
    "    L.seed_everything(cfg.utils.seed)\n",
    "    train_pyd = hydra.utils.instantiate(cfg.dataset, split='train')\n",
    "    cfg = interpolate(cfg, train_pyd)\n",
    "    del train_pyd\n",
    "    trainer = L.Trainer(devices=[int(device[-1])])\n",
    "    LM = SupervisedTask.load_from_checkpoint(cfg.best_model_path, map_location=torch.device(device))\n",
    "    model = LM.model\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cfg.optimizer.batch_size = 2048\n",
    "    cfg.dataset.config.label = 'future_1_365_any_below_40'\n",
    "\n",
    "    if site['split'] == 'mimic': \n",
    "        cfg.dataset.config.datadir = '/storage/shared/mimic/'\n",
    "        cfg.dataset.config.ecg.storedir = '/storage/shared/mimic/raw/ecg/'\n",
    "\n",
    "    pyd = hydra.utils.instantiate(cfg.dataset, split=site['split'])\n",
    "    pyd.data = pyd.data.reset_index(drop=1)\n",
    "    assert len(pyd)\n",
    "    site['pyd'] = pyd\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset = pyd,\n",
    "        batch_size = cfg.optimizer.batch_size,\n",
    "        num_workers = 0, \n",
    "        collate_fn = pyd.collate,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    out = trainer.predict(LM, loader)\n",
    "    site['pred'] = np.array(torch.sigmoid(torch.cat([x[0] for x in out])).tolist())\n",
    "    site['true'] = np.array(torch.cat([x[1] for x in out]).tolist())\n",
    "\n",
    "    site['idx_all'] = site['pyd'].data.index.values\n",
    "    site['idx_improve'] = site['pyd'].data.query('tag_hfref').index.values\n",
    "    site['idx_worsen'] = site['pyd'].data.query('~tag_hfref').index.values\n",
    "    # site['idx_worsen_50'] = site['pyd'].data.query('tag_50==True').index.values\n",
    "    # site['idx_worsen_no_com'] = site['pyd'].data.query('~tag_hfref').query('hypertension==0').query('diabetes_mellitus==0').query('atheroscler==0').query('chronic_obstructive_pulmonary_disease==0').query('atrial_fibrillation==0').index.values\n",
    "    # site['idx_worsen_no_med'] = site['pyd'].data.query('~tag_hfref').query('angio==0').query('betablocker==0').query('mra==0').query('diuretic==0').index.values\n",
    "    # site['idx_worsen_healthy'] = site['pyd'].data.query('~tag_hfref').query('angio==0').query('betablocker==0').query('mra==0').query('diuretic==0').query('hypertension==0').query('diabetes_mellitus==0').query('atheroscler==0').query('chronic_obstructive_pulmonary_disease==0').query('atrial_fibrillation==0').index.values\n",
    "\n",
    "    for cohort in COHORTS:\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        if cohort=='improve': \n",
    "            true = 1 - true \n",
    "            pred = 1 - pred\n",
    "        x = {}\n",
    "        x['fpr'], x['tpr'], x['thresholds'] = roc_curve(true, pred)\n",
    "        x['sens_to_thres'] = {}\n",
    "        sensitivities = x['tpr']\n",
    "        for i in np.concatenate([np.arange(0.1, 1, 0.1)]):\n",
    "            i = round(i, 2)\n",
    "            tol = 1e-10\n",
    "            matches = np.array([])\n",
    "            while not matches.any(): \n",
    "                matches = np.where(np.isclose(sensitivities, i, atol=tol, rtol=tol))[0]\n",
    "                tol *= 10\n",
    "            x['sens_to_thres'][i] = np.round(np.mean(np.unique(np.round(x['thresholds'][matches],2))),3)\n",
    "        site[cohort] = x\n",
    "    train_data = site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'name': 'MGH', 'split': 'train', 'line': '-',  \n",
    "'all': {'sens_to_thres': {0.1: 0.96, 0.2: 0.94, 0.3: 0.91, 0.4: 0.87, 0.5: 0.81, 0.6: 0.73, 0.7: 0.61, 0.8: 0.44, 0.9: 0.21}},\n",
    "'worsen': { 'sens_to_thres': {0.1: 0.955, 0.2: 0.89, 0.3: 0.8, 0.4: 0.68, 0.5: 0.56, 0.6: 0.43, 0.7: 0.29, 0.8: 0.17, 0.9: 0.07}}, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 140799\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3130017c2e3409e8808c43f2b7332e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 54\u001b[0m\n\u001b[1;32m     44\u001b[0m loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     45\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m pyd,\n\u001b[1;32m     46\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m out \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(LM, loader)\n\u001b[0;32m---> 54\u001b[0m site[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mcat([x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out]))\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     55\u001b[0m site[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(torch\u001b[38;5;241m.\u001b[39mcat([x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out])\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     57\u001b[0m site[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midx_all\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m site[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "sites = []\n",
    "for site in [\n",
    "    {\n",
    "        'name':'MGH',\n",
    "        'split':'test',\n",
    "        'line':'-',\n",
    "        'color':'#0F548D',\n",
    "    },\n",
    "    {\n",
    "        'name':'BWH',\n",
    "        'split':'external',\n",
    "        'line':'--',\n",
    "        'color':'#941751',\n",
    "    },\n",
    "    {\n",
    "        'name':'MIMIC',\n",
    "        'split':'mimic',\n",
    "        'line':'-.',\n",
    "        'color':'#4F8F00',\n",
    "    },\n",
    "]:\n",
    "    device = 'cuda:2'\n",
    "    cfg = OmegaConf.create(wandb.Api().run(WANDB_RUN).config)\n",
    "    L.seed_everything(cfg.utils.seed)\n",
    "    train_pyd = hydra.utils.instantiate(cfg.dataset, split='train')\n",
    "    cfg = interpolate(cfg, train_pyd)\n",
    "    del train_pyd\n",
    "    trainer = L.Trainer(devices=[int(device[-1])])\n",
    "    LM = SupervisedTask.load_from_checkpoint(cfg.best_model_path, map_location=torch.device(device))\n",
    "    model = LM.model\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cfg.optimizer.batch_size = 2048\n",
    "    cfg.dataset.config.label = 'future_1_365_any_below_40'\n",
    "\n",
    "    if site['split'] == 'mimic': \n",
    "        cfg.dataset.config.datadir = '/storage/shared/mimic/'\n",
    "        cfg.dataset.config.ecg.storedir = '/storage/shared/mimic/raw/ecg/'\n",
    "\n",
    "    pyd = hydra.utils.instantiate(cfg.dataset, split=site['split'])\n",
    "    pyd.data = pyd.data.reset_index(drop=1)\n",
    "    assert len(pyd)\n",
    "    site['pyd'] = pyd\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset = pyd,\n",
    "        batch_size = cfg.optimizer.batch_size,\n",
    "        num_workers = 0, \n",
    "        collate_fn = pyd.collate,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    out = trainer.predict(LM, loader)\n",
    "    site['pred'] = np.array(torch.sigmoid(torch.cat([x[0] for x in out])).tolist())\n",
    "    site['true'] = np.array(torch.cat([x[1] for x in out]).tolist())\n",
    "\n",
    "    site['idx_all'] = site['pyd'].data.index.values\n",
    "    # site['idx_improve'] = site['pyd'].data.query('tag_hfref').index.values\n",
    "    site['idx_worsen'] = site['pyd'].data.query('~tag_hfref').index.values\n",
    "    # site['idx_worsen_no_com'] = site['pyd'].data.query('~tag_hfref').query('hypertension==0').query('diabetes_mellitus==0').query('atheroscler==0').query('chronic_obstructive_pulmonary_disease==0').query('atrial_fibrillation==0').index.values\n",
    "    # site['idx_worsen_no_med'] = site['pyd'].data.query('~tag_hfref').query('angio==0').query('betablocker==0').query('mra==0').query('diuretic==0').index.values\n",
    "    # site['idx_worsen_healthy'] = site['pyd'].data.query('~tag_hfref').query('angio==0').query('betablocker==0').query('mra==0').query('diuretic==0').query('hypertension==0').query('diabetes_mellitus==0').query('atheroscler==0').query('chronic_obstructive_pulmonary_disease==0').query('atrial_fibrillation==0').index.values\n",
    "\n",
    "    sites.append(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions \n",
    "\n",
    "def read_lvef(split): \n",
    "    if split == 'mimic': \n",
    "        lvef = pl.read_csv(\n",
    "            '/storage/shared/mimic/raw/lvef.csv'\n",
    "        ).rename({\n",
    "            'subject_id':'empi',\n",
    "            'study_datetime':'lvef_date',\n",
    "            'result':'lvef'\n",
    "        }).drop(\n",
    "            'measurement'\n",
    "        ).filter(\n",
    "            pl.col('lvef').is_not_null()\n",
    "        ).with_columns(\n",
    "            pl.col('lvef').cast(pl.Int64),\n",
    "            pl.col(\"lvef_date\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S\").dt.date()\n",
    "        ).filter(\n",
    "            (pl.col('lvef')>0) & (pl.col('lvef')<100)\n",
    "        ).sort('lvef_date')\n",
    "    else: \n",
    "        lvef = pl.read_parquet('/storage2/payal/dropbox/private/data/processed/lvef.parquet').sort('lvef_date') \n",
    "    return lvef\n",
    "\n",
    "def create_bootstrap_idx(length, N=1000): \n",
    "    return [np.random.choice(length, length, replace=True) for _ in range(N)]\n",
    "\n",
    "def bootstrap(metric_fn, true, pred, idx=None, conf=0.95, **kwargs): \n",
    "    score = metric_fn(true=true, pred=pred, **kwargs)\n",
    "    if idx is None: \n",
    "        idx = create_bootstrap_idx(length=len(true), N=1000)\n",
    "    scores = [metric_fn(true[x], pred[x], **kwargs) for x in idx]\n",
    "    scores = sorted([x for x in scores if x is not None])\n",
    "    N = len(scores)\n",
    "    lower_idx = int(N * (1 - conf) / 2)\n",
    "    lower = np.abs(scores[lower_idx] - score)\n",
    "    upper_idx = int(N * (1 + conf) / 2)\n",
    "    upper = np.abs(scores[upper_idx] - score)\n",
    "    return score, (lower, upper)\n",
    "\n",
    "def conf_matrix(true, pred, threshold): \n",
    "    pred_labels = (pred >= threshold).astype(int)\n",
    "    tn = np.sum((pred_labels == 0) & (true == 0))\n",
    "    fp = np.sum((pred_labels == 1) & (true == 0))\n",
    "    fn = np.sum((pred_labels == 0) & (true == 1))\n",
    "    tp = np.sum((pred_labels == 1) & (true == 1))\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def get_auc(true, pred):\n",
    "    prev = true.sum()/len(true)\n",
    "    if prev==0 or prev==1: return None \n",
    "    return roc_auc_score(true, pred)\n",
    "\n",
    "def get_auprc(true, pred): \n",
    "    return average_precision_score(true, pred)\n",
    "\n",
    "def get_sens(true, pred, **kwargs): \n",
    "    tn, fp, fn, tp = conf_matrix(true, pred, kwargs['threshold'])\n",
    "    sens = tp / (tp + fn)\n",
    "    return sens\n",
    "\n",
    "def get_spec(true, pred, **kwargs): \n",
    "    tn, fp, fn, tp = conf_matrix(true, pred, kwargs['threshold'])\n",
    "    spec = tn / (tn + fp)\n",
    "    return spec\n",
    "\n",
    "def get_ppv(true, pred, **kwargs): \n",
    "    prev = kwargs['prevalence']\n",
    "    tn, fp, fn, tp = conf_matrix(true, pred, kwargs['threshold'])\n",
    "    sens = tp / (tp + fn)\n",
    "    spec = tn / (tn + fp)\n",
    "    ppv = (sens * prev) / (sens * prev + (1 - spec) * (1 - prev)) \n",
    "    return ppv \n",
    "\n",
    "def get_npv(true, pred, **kwargs): \n",
    "    prev = kwargs['prevalence']\n",
    "    tn, fp, fn, tp = conf_matrix(true, pred, kwargs['threshold'])\n",
    "    sens = tp / (tp + fn)\n",
    "    spec = tn / (tn + fp)\n",
    "    npv = (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev) \n",
    "    return npv\n",
    "\n",
    "def get_metric(name, cohort=None, verbose=False): \n",
    "    my_sites = sites\n",
    "    data = []\n",
    "    for x in my_sites: \n",
    "        if cohort is not None: x = x[cohort]\n",
    "        if name not in x: \n",
    "            continue \n",
    "        data.append(x[name])\n",
    "    if data:\n",
    "        if isinstance(data[0], (int)): data = [round(x) for x in data]\n",
    "        if isinstance(data[0], (float)): data = [round(x,3) for x in data]\n",
    "        if 'cf_' in name: name = name.replace('cf_','').split('_')[0]\n",
    "        if verbose: print(name, \" \".join([str(x) for x in data]))\n",
    "        return data\n",
    "    \n",
    "def get_metric_ci(name, cohort=None): \n",
    "    return np.array(get_metric(name+'_ci', cohort)).T\n",
    "\n",
    "def barplot(x, y, percent=False, decimal=0, ylim=None, yerr=None, colors=None):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    if colors is None: colors = sns.color_palette(\"Blues_r\", len(x))\n",
    "    else: colors = colors[:len(x)] \n",
    "    ax = sns.barplot(x=x, y=y, palette=colors, ax=ax)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    if yerr is not None:\n",
    "        x_coords = [p.get_x() + 0.5 * p.get_width() for p in ax.patches]\n",
    "        y_coords = [p.get_height() for p in ax.patches]\n",
    "        plt.errorbar(x=x_coords, y=y_coords, yerr=yerr, fmt=\"none\", c=\"k\", capsize=5)\n",
    "    ymin, ymax = ax.get_ylim() if ylim is None else ylim\n",
    "    annotation_y = ymin + (ymax - ymin) * 0.025  \n",
    "    for p in ax.patches:\n",
    "        label = round(p.get_height(), decimal) if decimal else round(p.get_height())\n",
    "        ax.annotate(f\"{label}{'%' if percent else ''}\", \n",
    "                    (p.get_x() + p.get_width() / 2, annotation_y), \n",
    "                    ha=\"center\", va=\"bottom\", fontsize=12, fontweight=\"bold\")\n",
    "    sns.despine()\n",
    "    return fig\n",
    "\n",
    "def generate_shades(hex_color, n=3, factor=0.15):\n",
    "    rgb = mcolors.hex2color(hex_color)\n",
    "    shades = [(min(1, c + factor * i)) for i in range(1, n+1) for c in rgb]\n",
    "    shades = [mcolors.to_hex(shades[i:i+3]) for i in range(0, len(shades), 3)]\n",
    "    return shades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished MGH\n",
      "Finished BWH\n"
     ]
    }
   ],
   "source": [
    "for num in range(len(sites)): \n",
    "    site = sites[num]\n",
    "    for cohort in COHORTS:\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        bootstrap_idx = create_bootstrap_idx(len(true))\n",
    "\n",
    "        if cohort=='improve': \n",
    "            true = 1 - true \n",
    "            pred = 1 - pred\n",
    "    \n",
    "        x = {}\n",
    "        x['samples'] = len(true)\n",
    "        x['prevalence'] = true.sum()/len(true)\n",
    "        x['auc'], x['auc_ci'] = bootstrap(get_auc, true, pred, bootstrap_idx)\n",
    "        x['auprc'], x['auprc_ci'] = bootstrap(get_auprc, true, pred, bootstrap_idx)\n",
    "        x['fpr'], x['tpr'], x['thresholds'] = roc_curve(true, pred)\n",
    "        \n",
    "        s2t = train_data[cohort]['sens_to_thres']\n",
    "\n",
    "        x['sensitivity'], x['sensitivity_ci'] = [], []\n",
    "        x['specificity'], x['specificity_ci'] = [], []\n",
    "        for _, threshold in s2t.items(): \n",
    "            sens, sens_ci = bootstrap(get_sens, true, pred, bootstrap_idx, threshold=threshold)\n",
    "            x['sensitivity'].append(sens)\n",
    "            x['sensitivity_ci'].append(sens_ci)\n",
    "            spec, spec_ci = bootstrap(get_spec, true, pred, bootstrap_idx, threshold=threshold)\n",
    "            x['specificity'].append(spec)\n",
    "            x['specificity_ci'].append(spec_ci)\n",
    "\n",
    "        for desired_sens in [.7,.8,.9]: \n",
    "            prefix = f'sens_{round(desired_sens*100)}'\n",
    "            threshold = s2t[desired_sens]\n",
    "\n",
    "            # x[f'{prefix}_spec'], x[f'{prefix}_spec_ci'] = bootstrap(get_spec, true, pred, bootstrap_idx, threshold=threshold)\n",
    "            x[f'{prefix}_ppv'], x[f'{prefix}_ppv_ci'] = bootstrap(get_ppv, true, pred, bootstrap_idx, threshold=threshold, prevalence=x['prevalence'])\n",
    "            x[f'{prefix}_npv'], x[f'{prefix}_npv_ci'] = bootstrap(get_npv, true, pred, bootstrap_idx, threshold=threshold, prevalence=x['prevalence'])\n",
    "\n",
    "            for prev in np.arange(0.1,1,.05):\n",
    "                prev = round(prev,2)\n",
    "                x[f'{prefix}_prev_{prev}_ppv'], x[f'{prefix}_prev_{prev}_ppv_ci'] = bootstrap(get_ppv, true, pred, bootstrap_idx, threshold=threshold, prevalence=prev)\n",
    "                x[f'{prefix}_prev_{prev}_npv'], x[f'{prefix}_prev_{prev}_npv_ci'] = bootstrap(get_npv, true, pred, bootstrap_idx, threshold=threshold, prevalence=prev)\n",
    "\n",
    "        sites[num][cohort] = x\n",
    "\n",
    "    print(f\"Finished {sites[num]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "all\n",
      "----------------------------------------\n",
      "paced==True \t 92.7 ± 0.7 \t 92.4 ± 0.5\n",
      "paced==False \t 92.9 ± 0.2 \t 91.9 ± 0.2\n",
      "afib==True \t 92.0 ± 0.8 \t 91.5 ± 0.4\n",
      "afib==False \t 93.1 ± 0.2 \t 92.3 ± 0.2\n",
      "----------------------------------------\n",
      "worsen\n",
      "----------------------------------------\n",
      "paced==True \t 87.3 ± 1.7 \t 88.3 ± 0.8\n",
      "paced==False \t 89.5 ± 0.5 \t 89.2 ± 0.3\n",
      "afib==True \t 88.8 ± 1.3 \t 87.9 ± 0.6\n",
      "afib==False \t 89.5 ± 0.4 \t 89.5 ± 0.3\n"
     ]
    }
   ],
   "source": [
    "# confounder auc in all patients \n",
    "confounders = [\n",
    "    # 'mean_annual_hospitalizations<1',\n",
    "    # 'mean_annual_hospitalizations>=1',\n",
    "    'paced==True',\n",
    "    'paced==False',\n",
    "    'afib==True',\n",
    "    'afib==False',\n",
    "    # 'transplant==0',\n",
    "    # 'transplant==1',\n",
    "    # 'diabetes_mellitus==0',\n",
    "    # 'diabetes_mellitus==1',\n",
    "    # 'hypertension==0',\n",
    "    # 'hypertension==1',\n",
    "    # 'atheroscler==0',\n",
    "    # 'atheroscler==1',\n",
    "    # 'chronic_obstructive_pulmonary_disease==0',\n",
    "    # 'chronic_obstructive_pulmonary_disease==1',\n",
    "    # 'atrial_fibrillation==0',\n",
    "    # 'atrial_fibrillation==1',\n",
    "    # 'num_meds==0',\n",
    "    # 'num_meds>0',\n",
    "    # 'angio==0',\n",
    "    # 'angio==1',\n",
    "    # 'mra==0',\n",
    "    # 'mra==1',\n",
    "    # 'betablocker==0',\n",
    "    # 'betablocker==1',\n",
    "    # 'diuretic==0',\n",
    "    # 'diuretic==1',\n",
    "]\n",
    "for cohort in ['all','worsen']:\n",
    "    print('-'*40)\n",
    "    print(cohort)\n",
    "    print('-'*40)\n",
    "    for cf in confounders:\n",
    "        result = [cf,] \n",
    "        for site in sites:\n",
    "            idx = site[f\"idx_{cohort}\"]\n",
    "            try: site['pyd'].data.query(cf)\n",
    "            except: continue \n",
    "            cf_idx = np.intersect1d(idx, site['pyd'].data.query(cf).index.values)\n",
    "            cf_true = site['true'][cf_idx]\n",
    "            cf_pred = site['pred'][cf_idx]\n",
    "            try: roc_auc_score(cf_true, cf_pred)\n",
    "            except: continue \n",
    "            auc, ci = bootstrap(get_auc, cf_true, cf_pred)\n",
    "            delta = np.mean(ci)\n",
    "            result.append(f\"\\t {round(auc*100, 1)} ± {round(delta*100, 1)}\")\n",
    "        print(*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bars\n",
    "for cohort in COHORTS:\n",
    "    print(cohort)\n",
    "    fig = barplot(\n",
    "        x=get_metric('name'), \n",
    "        y=get_metric('samples',cohort),\n",
    "        ylim=(0,100000),\n",
    "        colors=get_metric('color'), \n",
    "    )\n",
    "    plt.show()\n",
    "    fig = barplot(\n",
    "        x=get_metric('name'), \n",
    "        y=[100*i for i in get_metric('prevalence',cohort)], \n",
    "        percent=True, \n",
    "        decimal=1, \n",
    "        ylim=(0,100),\n",
    "        colors=get_metric('color'), \n",
    "    )\n",
    "    plt.show()\n",
    "    fig = barplot(\n",
    "        x=get_metric('name'), \n",
    "        y=[100*i for i in get_metric('auc',cohort)], \n",
    "        yerr=100* get_metric_ci('auc',cohort), \n",
    "        percent=True, \n",
    "        decimal=1, \n",
    "        ylim=(50,100),\n",
    "        colors=get_metric('color'), \n",
    "    )\n",
    "    plt.show()\n",
    "    fig = barplot(\n",
    "        x=get_metric('name'), \n",
    "        y=[100*i for i in get_metric('auprc',cohort)], \n",
    "        yerr=100* get_metric_ci('auprc',cohort), \n",
    "        percent=True, \n",
    "        decimal=1, \n",
    "        ylim=(0,100),\n",
    "        colors=get_metric('color'), \n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sens sens\n",
    "for cohort in COHORTS:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        data = site[cohort]\n",
    "        prev = np.round(np.arange(0.1, 1, 0.1), 1)\n",
    "        sens_levels = [70, 80, 90]\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        x = data[f'sensitivity']\n",
    "        x_err = np.array(data[f'sensitivity_ci']).T\n",
    "        plt.errorbar(\n",
    "            np.arange(0.1, 1, 0.1),\n",
    "            x,\n",
    "            yerr=x_err,\n",
    "            capsize=3,\n",
    "            marker=\"o\",\n",
    "            markersize=3,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=1,\n",
    "            color=site['color'],\n",
    "        )\n",
    "        ax.set_xlabel(\"Sensitivity @ Training\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Sensitivity @ Evaluation\", fontsize=12, color='gray')\n",
    "        ax.set_title(f\"{site['name']}\", fontsize=14)\n",
    "        ax.set_ylim(0, 1.025)\n",
    "        ax.set_xlim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sens spec\n",
    "for cohort in COHORTS:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        data = site[cohort]\n",
    "        prev = np.round(np.arange(0.1, 1, 0.1), 1)\n",
    "        sens_levels = [70, 80, 90]\n",
    "        spec = data[f'specificity']\n",
    "        spec_err = np.array(data[f'specificity_ci']).T\n",
    "        plt.errorbar(\n",
    "            np.arange(0.1, 1, 0.1),\n",
    "            spec,\n",
    "            yerr=spec_err,\n",
    "            capsize=3,\n",
    "            marker=\"o\",\n",
    "            markersize=3,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=1,\n",
    "            color=site['color'],\n",
    "        )\n",
    "        ax.set_xlabel(\"Sensitivity\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Specificity\", fontsize=12, color='gray')\n",
    "        # ax.set_title(f\"{site['name']}\", fontsize=14)\n",
    "        ax.set_ylim(0, 1.025)\n",
    "        ax.set_xlim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppv\n",
    "for cohort in COHORTS:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        data = site[cohort]\n",
    "        prev = np.round(np.arange(0.1, 1, 0.1), 1)\n",
    "        sens_levels = [70, 80, 90]\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        for sens in sens_levels:\n",
    "            ppv = np.array([data[f'sens_{sens}_prev_{i}_ppv'] for i in prev])\n",
    "            ppv_err = np.array([data.get(f'sens_{sens}_prev_{i}_ppv_ci') for i in prev])\n",
    "            plt.errorbar(\n",
    "                prev,\n",
    "                ppv,\n",
    "                yerr=ppv_err.T,\n",
    "                label=f\"Sensitivity {sens}%\",\n",
    "                capsize=3,\n",
    "                marker=\"o\",\n",
    "                markersize=3,\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                color=site['color'],\n",
    "            )\n",
    "            plt.text(\n",
    "                0.15,\n",
    "                ppv[0]+0.05,  \n",
    "                f\"{sens}%\",\n",
    "                fontsize=10,\n",
    "                color=site['color'],\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                bbox=dict(boxstyle=\"round,pad=0.1\", edgecolor=\"none\", facecolor=\"white\", alpha=0.7),\n",
    "            )\n",
    "        ax.set_xlabel(\"Prevalence\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Positive Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(f\"{site['name']}\", fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # handles = [h[0] for h in handles]\n",
    "        # ax.legend(handles, labels, markerscale=0.001)\n",
    "        plt.grid(True)\n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npv\n",
    "for cohort in COHORTS:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        data = site[cohort]\n",
    "        prev = np.round(np.arange(0.1, 1, 0.1), 1)\n",
    "        sens_levels = [70, 80, 90]\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        for sens in sens_levels:\n",
    "            npv = np.array([data[f'sens_{sens}_prev_{i}_npv'] for i in prev])\n",
    "            npv_err = np.array([data.get(f'sens_{sens}_prev_{i}_npv_ci') for i in prev])\n",
    "            plt.errorbar(\n",
    "                prev,\n",
    "                npv,\n",
    "                yerr=npv_err.T,\n",
    "                label=f\"Sensitivity {sens}%\",\n",
    "                capsize=3,\n",
    "                marker=\"o\",\n",
    "                markersize=3,\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                color=site['color'],\n",
    "            )\n",
    "            plt.text(\n",
    "                0.8,\n",
    "                npv[-2],  \n",
    "                f\"{sens}%\",\n",
    "                fontsize=10,\n",
    "                color=site['color'],\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                bbox=dict(boxstyle=\"round,pad=0.1\", edgecolor=\"none\", facecolor=\"white\", alpha=0.7),\n",
    "            )\n",
    "        ax.set_xlabel(\"Prevalence\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Negative Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(f\"{site['name']}\", fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "        # handles = [h[0] for h in handles]\n",
    "        # ax.legend(handles, labels, markerscale=0.001)\n",
    "        plt.grid(True)\n",
    "        sns.despine()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print specificity\n",
    "for cohort in COHORTS:\n",
    "    print(f\"\\nCohort: {cohort}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    sensitivities = [10,20,30,40,50,60,70, 80, 90]\n",
    "    \n",
    "    for i, sens in enumerate(sensitivities):\n",
    "        if sens<65: continue\n",
    "        print(f\"\\nSensitivity: {sens}%\")\n",
    "        for site_name, site in zip([\"MGH\", \"BWH\", \"MIMIC\"], sites):\n",
    "            specificity = site[cohort]['specificity'][i]\n",
    "            lower_ci, upper_ci = site[cohort]['specificity_ci'][i]\n",
    "            print(f\"  {site_name}: Specificity = {specificity:.3f} (95% CI: [{lower_ci:.3f}, {upper_ci:.3f}])\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ppv npv\n",
    "for cohort in COHORTS:\n",
    "    print(f\"\\nCohort: {cohort}\")\n",
    "    print(\"=\" * 40)\n",
    "    model_names = get_metric('name')  # Retrieve model names\n",
    "\n",
    "    for prev in [0.1]:\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"\\nPrevalence: {prev*100}%\")\n",
    "        for metric in ['ppv', 'npv']:\n",
    "            for sens in [70,80,90]: \n",
    "                x = get_metric(f'sens_{sens}_prev_{prev}_{metric}', cohort)\n",
    "                x_err = get_metric_ci(f'sens_{sens}_prev_{prev}_{metric}', cohort)\n",
    "\n",
    "                print(f\"\\nSensitivity: {sens}%\")\n",
    "                print(f\"{metric} {min(x)*100:.1f}%–{max(x)*100:.1f}%\")\n",
    "                # for name, val, ci_low, ci_high in zip(model_names, x, x_err[0], x_err[1]):\n",
    "                #     print(f\"  {name}: {metric} = {val:.3f} (95% CI: [{val - ci_low:.3f}, {val + ci_high:.3f}])\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total positives in last N years\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "N_YEARS = 2\n",
    "\n",
    "for cohort in COHORTS:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4), sharex=False)\n",
    "\n",
    "        shades = generate_shades(site['color'], n=3)\n",
    "    \n",
    "        for sens, color in zip([.7, .8, .9], reversed(shades)): \n",
    "            threshold = train_data[cohort]['sens_to_thres'][sens]\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            df = pl.from_pandas(df)\n",
    "\n",
    "            total_positives = []\n",
    "            for group in df.group_by(\"empi\"):\n",
    "                ecg = group[1].sort(\"ecg_date\")\n",
    "                for idx in range(ecg.height): \n",
    "                    start_date = ecg[idx, \"ecg_date\"]\n",
    "                    max_date = start_date + timedelta(days=N_YEARS*365)\n",
    "                    \n",
    "                    pos_count = (\n",
    "                        ecg.filter(\n",
    "                            (pl.col(\"ecg_date\") >= start_date) & \n",
    "                            (pl.col(\"ecg_date\") <= max_date) &\n",
    "                            (pl.col(\"pred\") == True)  # Only count positive predictions\n",
    "                        )\n",
    "                        .with_row_count(name='pos_count', offset=1)\n",
    "                        .select([\"pos_count\", \"empi\", \"true\", \"pred\"])\n",
    "                    )\n",
    "                    total_positives.append(pos_count)\n",
    "\n",
    "            total_positives = pl.concat(total_positives)\n",
    "\n",
    "            PPVs = []\n",
    "            bins = []\n",
    "            step=1\n",
    "            for st in range(1, 4, step): \n",
    "                end = st + step \n",
    "                bins.append((st,end))\n",
    "            bins.append((3,20))\n",
    "            for st, end in bins:\n",
    "                x = total_positives.filter(pl.col('pos_count').is_between(st, end, closed='left'))\n",
    "                if not x.height: \n",
    "                    continue \n",
    "                ppv = x.filter(pl.col('true')==1).height/x.height\n",
    "                if end-st <= 1 : \n",
    "                    label = f\"{st}\"\n",
    "                else: \n",
    "                    label = f\"{st}+\"\n",
    "                PPVs.append((label, ppv))\n",
    "                print(label, ppv)\n",
    "\n",
    "            ax = sns.barplot(x=[x[0] for x in PPVs], y=[x[1] for x in PPVs], label=sens, color=color, ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"Cumulative positives\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Positive Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(site['name'], fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        ax.grid(axis='y', linestyle='--')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # plt.ylim(0.5, 1)\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total negatives in last N years\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "N_YEARS = 2\n",
    "\n",
    "for cohort in COHORTS:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4), sharex=False)\n",
    "\n",
    "        shades = generate_shades(site['color'], n=3)\n",
    "        for sens, color in zip([.9, .8, .7], shades): \n",
    "            threshold = train_data[cohort]['sens_to_thres'][sens]\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            df = pl.from_pandas(df)\n",
    "\n",
    "            total_negatives = []\n",
    "            for group in df.group_by(\"empi\"):\n",
    "                ecg = group[1].sort(\"ecg_date\")\n",
    "                for idx in range(ecg.height): \n",
    "                    start_date = ecg[idx, \"ecg_date\"]\n",
    "                    max_date = start_date + timedelta(days=N_YEARS * 365)\n",
    "                    \n",
    "                    neg_count = (\n",
    "                        ecg.filter(\n",
    "                            (pl.col(\"ecg_date\") >= start_date) & \n",
    "                            (pl.col(\"ecg_date\") <= max_date) &\n",
    "                            (pl.col(\"pred\") == False)  # Only count positive predictions\n",
    "                        )\n",
    "                        .with_row_count(name='neg_count', offset=1)\n",
    "                        .select([\"neg_count\", \"empi\", \"true\", \"pred\"])\n",
    "                    )\n",
    "                    total_negatives.append(neg_count)\n",
    "\n",
    "            total_negatives = pl.concat(total_negatives)\n",
    "\n",
    "            NPVs = []\n",
    "            bins = []\n",
    "            step=1\n",
    "            for st in range(1, 4, step): \n",
    "                end = st + step \n",
    "                bins.append((st,end))\n",
    "            bins.append((3,20))\n",
    "            for st, end in bins:\n",
    "                x = total_negatives.filter(pl.col('neg_count').is_between(st, end, closed='left'))\n",
    "                if not x.height: \n",
    "                    continue \n",
    "                npv = x.filter(pl.col('true')==0).height/x.height\n",
    "                if end-st <= 1 : \n",
    "                    label = f\"{st}\"\n",
    "                else: \n",
    "                    label = f\"{st}+\"\n",
    "                NPVs.append((label, npv))\n",
    "                print(label, npv)\n",
    "\n",
    "            ax = sns.barplot(x=[x[0] for x in NPVs], y=[x[1] for x in NPVs], label=sens, color=color, ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"Cumulative negatives\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Negative Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(site['name'], fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        ax.grid(axis='y', linestyle='--')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # plt.ylim(0.5, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 years \n",
    "\n",
    "# total positives in last N years \n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "for cohort in ['all']:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4), sharex=False)\n",
    "\n",
    "        shades = generate_shades(site['color'], n=3)\n",
    "    \n",
    "        for sens, color in zip([.7, .8, .9], reversed(shades)): \n",
    "            threshold = train_data[cohort]['sens_to_thres'][sens]\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            df = pl.from_pandas(df)\n",
    "\n",
    "            total_positives = []\n",
    "            for group in df.group_by(\"empi\"):\n",
    "                ecg = group[1].sort(\"ecg_date\")\n",
    "                for idx in range(ecg.height): \n",
    "                    start_date = ecg[idx, \"ecg_date\"]\n",
    "                    max_date = start_date + timedelta(days=5 * 365)\n",
    "                    \n",
    "                    pos_count = (\n",
    "                        ecg.filter(\n",
    "                            (pl.col(\"ecg_date\") >= start_date) & \n",
    "                            (pl.col(\"ecg_date\") <= max_date) &\n",
    "                            (pl.col(\"pred\") == True)  # Only count positive predictions\n",
    "                        )\n",
    "                        .with_row_count(name='pos_count', offset=1)\n",
    "                        .select([\"pos_count\", \"empi\", \"true\", \"pred\"])\n",
    "                    )\n",
    "                    total_positives.append(pos_count)\n",
    "\n",
    "            total_positives = pl.concat(total_positives)\n",
    "\n",
    "            PPVs = []\n",
    "            step = 5\n",
    "            for st in range(0, 50, step): \n",
    "                end = st + step \n",
    "                if st==0: st=1\n",
    "                x = total_positives.filter(pl.col('pos_count').is_between(st, end, closed='left'))\n",
    "                ppv = x.filter(pl.col('true')==1).height/x.height\n",
    "                PPVs.append((f\"{st}-{end}\", ppv))\n",
    "\n",
    "            ax = sns.barplot(x=[x[0] for x in PPVs], y=[x[1] for x in PPVs], label=sens, color=color, ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"Cumulative positives\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Positive Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(site['name'], fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # plt.ylim(0.5, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat positives last 1 years \n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "for cohort in ['worsen']:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4), sharex=False)\n",
    "\n",
    "        shades = generate_shades(site['color'], n=3)\n",
    "    \n",
    "        for sens, color in zip([.7, .8, .9], reversed(shades)): \n",
    "            threshold = train_data[cohort]['sens_to_thres'][sens]\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            df = pl.from_pandas(df)\n",
    "\n",
    "            repeat_positives = []\n",
    "            for group in df.group_by(\"empi\"):\n",
    "                ecg = group[1].sort(\"ecg_date\")\n",
    "                for idx in range(ecg.height): \n",
    "                    start_date = ecg[idx, \"ecg_date\"]\n",
    "                    max_date = start_date + timedelta(days=1 * 365)\n",
    "                    chunk = ecg.filter(\n",
    "                        (pl.col(\"ecg_date\") >= start_date) & \n",
    "                        (pl.col(\"ecg_date\") <= max_date)\n",
    "                    ).with_columns(\n",
    "                        (pl.col('pred').eq(True).cum_sum()).alias(\"keep\")\n",
    "                    ).filter(\n",
    "                        pl.col(\"keep\") > 0\n",
    "                    ).drop(\n",
    "                        \"keep\"\n",
    "                    ).with_columns(\n",
    "                        (pl.col('pred').eq(False).cum_sum()).alias(\"keep\")\n",
    "                    ).filter(\n",
    "                        pl.col(\"keep\") == 0\n",
    "                    ).drop(\n",
    "                        \"keep\"\n",
    "                    ).with_row_count(\n",
    "                        name='pos_count',offset=1\n",
    "                    ).select(\n",
    "                        ['pos_count','empi','true','pred']\n",
    "                    )\n",
    "                    repeat_positives.append(chunk)\n",
    "            repeat_positives = pl.concat(repeat_positives)\n",
    "\n",
    "            PPVs = []\n",
    "            step = 1\n",
    "            for st in range(0, 10, step): \n",
    "                end = st + step \n",
    "                if st==0: st=1\n",
    "                x = total_positives.filter(pl.col('pos_count').is_between(st, end, closed='left'))\n",
    "                if not x.height: \n",
    "                    continue \n",
    "                ppv = x.filter(pl.col('true')==1).height/x.height\n",
    "                if end-st <= 1 : \n",
    "                    label = f\"{st}\"\n",
    "                else: \n",
    "                    label = f\"{st}-{end}\"\n",
    "                PPVs.append((label, ppv))\n",
    "\n",
    "            ax = sns.barplot(x=[x[0] for x in PPVs], y=[x[1] for x in PPVs], label=sens, color=color, ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"Successive positives\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Positive Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(site['name'], fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # plt.ylim(0.5, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat positives \n",
    "for cohort in ['worsen']:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4), sharex=False)\n",
    "\n",
    "        shades = generate_shades(site['color'], n=3)\n",
    "    \n",
    "        for sens, color in zip([.7, .8, .9], reversed(shades)): \n",
    "            threshold = train_data[cohort]['sens_to_thres'][sens]\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            df = pl.from_pandas(df)\n",
    "\n",
    "            repeat_positives = []\n",
    "            for group in df.group_by(\"empi\"): \n",
    "                x = group[1].sort(\n",
    "                    'ecg_date'\n",
    "                ).with_columns(\n",
    "                    (pl.col('pred').eq(True).cum_sum()).alias(\"keep\")\n",
    "                ).filter(\n",
    "                    pl.col(\"keep\") > 0\n",
    "                ).drop(\n",
    "                    \"keep\"\n",
    "                ).with_columns(\n",
    "                    (pl.col('pred').eq(False).cum_sum()).alias(\"keep\")\n",
    "                ).filter(\n",
    "                    pl.col(\"keep\") == 0\n",
    "                ).drop(\n",
    "                    \"keep\"\n",
    "                ).with_row_count(\n",
    "                    name='pos_count',offset=1\n",
    "                ).select(\n",
    "                    ['pos_count','empi','true','pred']\n",
    "                )\n",
    "                repeat_positives.append(x)\n",
    "            repeat_positives = pl.concat(repeat_positives)\n",
    "\n",
    "            PPVs = []\n",
    "            step = 5\n",
    "            for st in range(0, 50, step): \n",
    "                end = st + step \n",
    "                if st==0: st=1\n",
    "                x = repeat_positives.filter(pl.col('pos_count').is_between(st, end, closed='left'))\n",
    "                ppv = x.filter(pl.col('true')==1).height/x.height\n",
    "                PPVs.append((f\"{st}-{end}\", ppv))\n",
    "\n",
    "            ax = sns.barplot(x=[x[0] for x in PPVs], y=[x[1] for x in PPVs], label=sens, color=color, ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"Successive positives\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Positive Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(site['name'], fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # plt.ylim(0.5, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat negatives \n",
    "for cohort in ['all']:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,4), sharex=False)\n",
    "        shades = generate_shades(site['color'], n=3)\n",
    "        for sens, color in zip([.9, .8, .7], shades): \n",
    "            threshold = train_data[cohort]['sens_to_thres'][sens]\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            df = pl.from_pandas(df)\n",
    "\n",
    "            repeat_negatives = []\n",
    "            for group in df.group_by(\"empi\"): \n",
    "                x = group[1].sort(\n",
    "                    'ecg_date'\n",
    "                ).with_columns(\n",
    "                    (pl.col('pred').eq(False).cum_sum()).alias(\"keep\")\n",
    "                ).filter(\n",
    "                    pl.col(\"keep\") > 0\n",
    "                ).drop(\n",
    "                    \"keep\"\n",
    "                ).with_columns(\n",
    "                    (pl.col('pred').eq(True).cum_sum()).alias(\"keep\")\n",
    "                ).filter(\n",
    "                    pl.col(\"keep\") == 0\n",
    "                ).drop(\n",
    "                    \"keep\"\n",
    "                ).with_row_count(\n",
    "                    name='neg_count',offset=1\n",
    "                ).select(\n",
    "                    ['neg_count','empi','true','pred']\n",
    "                )\n",
    "                repeat_negatives.append(x)\n",
    "            repeat_negatives = pl.concat(repeat_negatives)\n",
    "\n",
    "            NPVs = []\n",
    "            step = 5\n",
    "            for st in range(0, 50, step): \n",
    "                end = st + step \n",
    "                if st==0: st=1\n",
    "                x = repeat_negatives.filter(pl.col('neg_count').is_between(st, end, closed='left'))\n",
    "                npv = x.filter(pl.col('true')==0).height/x.height\n",
    "                NPVs.append((f\"{st}-{end}\", npv))\n",
    "\n",
    "            ax = sns.barplot(x=[x[0] for x in NPVs], y=[x[1] for x in NPVs], label=sens, color=color, ax=ax)\n",
    "        \n",
    "        ax.set_xlabel(\"Successive negatives\", fontsize=12, color='gray')\n",
    "        ax.set_ylabel(\"Negative Predictive Value\", fontsize=12, color='gray')\n",
    "        ax.set_title(site['name'], fontsize=14)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.gca().tick_params(axis='y', colors='gray')\n",
    "        plt.gca().spines['left'].set_color('gray')\n",
    "        plt.gca().spines['left'].set_linewidth(1)\n",
    "        plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "        plt.gca().spines['bottom'].set_color('gray')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # plt.ylim(0.5, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat false positives \n",
    "for cohort in ['all']:\n",
    "    print(cohort)\n",
    "    for site in sites:\n",
    "        print(site['name'])\n",
    "        if f\"idx_{cohort}\" not in site: continue \n",
    "        idx = site[f\"idx_{cohort}\"]\n",
    "        set_idx = set(list(idx))\n",
    "        true = site['true'][idx]\n",
    "        pred = site['pred'][idx]\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6), sharex=False)\n",
    "        for (sens, threshold) in train_data[cohort]['sens_to_thres'].items(): \n",
    "            if sens!=.7: continue\n",
    "            # decision = pred>(1-threshold)\n",
    "            decision = pred>threshold\n",
    "            df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "            df.loc[:,'true'] = true\n",
    "            df.loc[:,'score'] = pred\n",
    "            df.loc[:,'pred'] = decision\n",
    "            print(get_sens(true, pred, threshold=threshold))\n",
    "            df = pl.from_pandas(df).with_columns(\n",
    "                pl.when(\n",
    "                    (pl.col('pred')!=pl.col('true')) # incorrect predictions \n",
    "                    &\n",
    "                    (pl.col('pred')==1) # predictions are that EF will fall\n",
    "                ).then(True).otherwise(False).alias('false_positive'),\n",
    "                pl.when(\n",
    "                    (pl.col('pred')==pl.col('true')) # correct predictions \n",
    "                    &\n",
    "                    (pl.col('pred')==0) # predictions are that EF stay > 40\n",
    "                ).then(True).otherwise(False).alias('true_negative'),\n",
    "            )\n",
    "\n",
    "            repeat_false_positives = []\n",
    "            for group in df.group_by(\"empi\"): \n",
    "                df = group[1].sort(['empi','ecg_date'])\n",
    "                fps = 0\n",
    "                first_ecg_date = None \n",
    "                for row in df.to_dicts(): \n",
    "                    if row['false_positive']: \n",
    "                        if fps == 0: \n",
    "                            first_ecg_date = row['ecg_date']\n",
    "                        fps += 1\n",
    "                        repeat_false_positives.append({\n",
    "                            'empi':row['empi'], \n",
    "                            'ecg_date':row['ecg_date'],\n",
    "                            'first_ecg_date':first_ecg_date,\n",
    "                            'fp_count':fps,\n",
    "                        })\n",
    "                    else: \n",
    "                        fps = 0\n",
    "\n",
    "            if site['split'] == 'mimic': \n",
    "                lvef = pl.read_csv(\n",
    "                    '/storage/shared/mimic/raw/lvef.csv'\n",
    "                ).rename({\n",
    "                    'subject_id':'empi',\n",
    "                    'study_datetime':'lvef_date',\n",
    "                    'result':'lvef'\n",
    "                }).drop(\n",
    "                    'measurement'\n",
    "                ).filter(\n",
    "                    pl.col('lvef').is_not_null()\n",
    "                ).with_columns(\n",
    "                    pl.col('lvef').cast(pl.Int64),\n",
    "                    pl.col(\"lvef_date\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S\").dt.date()\n",
    "                ).filter(\n",
    "                    (pl.col('lvef')>0) & (pl.col('lvef')<100)\n",
    "                ).sort('lvef_date')\n",
    "            else: \n",
    "                lvef = pl.read_parquet('/storage2/payal/dropbox/private/data/processed/lvef.parquet').sort('lvef_date') \n",
    "\n",
    "            N_values = []\n",
    "            examples = []\n",
    "            any_bad_percent = []\n",
    "            days_to_bad = []\n",
    "            for N in range(1,20): \n",
    "                N_fps = [x for x in repeat_false_positives if x['fp_count']==N]\n",
    "                if not len(N_fps): continue \n",
    "                any_bad_tally = 0\n",
    "                times_to_first_bad = []\n",
    "                for x in N_fps: \n",
    "                    date = x['first_ecg_date']\n",
    "                    lvef_after_warning = lvef.filter(pl.col('empi')==x['empi']).filter(pl.col('lvef_date')>=date)\n",
    "                    any_bad = not lvef_after_warning.filter(pl.col('lvef')<=40).is_empty()\n",
    "                    any_bad_tally += any_bad\n",
    "                    time_to_first_bad = None \n",
    "                    if any_bad: \n",
    "                        time_to_first_bad = lvef_after_warning.filter(pl.col('lvef')<=40).sort('lvef_date').head(1).select('lvef_date').item() - date.date()\n",
    "                        times_to_first_bad.append(time_to_first_bad)\n",
    "                percent = round(100*any_bad_tally/len(N_fps))\n",
    "                days = np.mean(times_to_first_bad).days if times_to_first_bad else 0\n",
    "                N_values.append(N)\n",
    "                any_bad_percent.append(percent)\n",
    "                days_to_bad.append(days)\n",
    "                examples.append(len(N_fps))\n",
    "            \n",
    "            x_max = max(N_values)+1\n",
    "            ax2.plot(N_values, any_bad_percent, marker='o', linestyle='-', label=sens, zorder=2)\n",
    "            # ax2.set_ylim(0, 105)\n",
    "            # ax2.set_xlim(0, x_max)\n",
    "            # ax2.set_xticks(range(0, x_max, 5))\n",
    "            # ax2.set_yticks(range(0, 101, 20))\n",
    "            ax2.set_title(\"How often is low LVEF observed in the future?\", fontsize=14)\n",
    "            ax2.set_xlabel(\"Subsequent false positive predictions\", fontsize=12)\n",
    "            ax2.set_ylabel(\"Percentage\", fontsize=12)\n",
    "            ax2.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "            ax2.spines['top'].set_visible(False)\n",
    "            ax2.spines['right'].set_visible(False)\n",
    "\n",
    "            ax3.plot(N_values, days_to_bad, marker='o', linestyle='-', label=sens, zorder=2)\n",
    "            ax3.set_xlim(0, 20)\n",
    "            ax3.set_ylim(0, 1000)\n",
    "            # ax3.set_xticks(range(0, x_max, 5))\n",
    "            ax3.set_title(f\"{site['name']}\", fontsize=14)\n",
    "            ax3.set_xlabel(\"Subsequent false positive predictions\", fontsize=12)\n",
    "            ax3.set_ylabel(\"Days\", fontsize=12)\n",
    "            ax3.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "            ax3.spines['top'].set_visible(False)\n",
    "            ax3.spines['right'].set_visible(False)\n",
    "\n",
    "            ax1.plot(N_values, examples, marker='o', linestyle='-', label=sens, zorder=2)\n",
    "            # ax1.set_ylim(0, max(examples) + 50)\n",
    "            # ax1.set_xlim(0, x_max)\n",
    "            # ax1.set_xticks(range(0, x_max, 5))\n",
    "            # ax1.set_yticks(range(0, max(examples) + 50, 100))\n",
    "            ax1.set_title(\"Number of examples for each N-value\", fontsize=14)\n",
    "            ax1.set_xlabel(\"Subsequent false positive predictions\", fontsize=12)\n",
    "            ax1.set_ylabel(\"Number of ECGs\", fontsize=12)\n",
    "            ax1.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "            ax1.spines['top'].set_visible(False)\n",
    "            ax1.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.legend([])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORs false positives \n",
    "import scipy.stats as stats\n",
    "\n",
    "cohort = 'all'\n",
    "\n",
    "for site in sites: \n",
    "    print(site['name'])\n",
    "\n",
    "    idx = site[f\"idx_{cohort}\"]\n",
    "    set_idx = set(list(idx))\n",
    "    true = site['true'][idx]\n",
    "    pred = site['pred'][idx]\n",
    "    for (sens, threshold) in train_data[cohort]['sens_to_thres'].items(): \n",
    "        if sens==.9: \n",
    "            break\n",
    "    # decision = pred>(1-threshold)\n",
    "    decision = pred>threshold\n",
    "    df = site['pyd'].data.loc[[x in set_idx for x in range(site['pyd'].data.shape[0])],:]\n",
    "    df.loc[:,'true'] = true\n",
    "    df.loc[:,'score'] = pred\n",
    "    df.loc[:,'pred'] = decision\n",
    "    df = pl.from_pandas(df).with_columns(\n",
    "        pl.when(\n",
    "            (pl.col('pred')!=pl.col('true')) # incorrect predictions \n",
    "            &\n",
    "            (pl.col('pred')==1) # predictions are that EF will fall\n",
    "        ).then(True).otherwise(False).alias('false_positive'),\n",
    "        pl.when(\n",
    "            (pl.col('pred')==pl.col('true')) # correct predictions \n",
    "            &\n",
    "            (pl.col('pred')==0) # predictions are that EF stay > 40\n",
    "        ).then(True).otherwise(False).alias('true_negative'),\n",
    "        pl.when(\n",
    "            (pl.col('pred')==pl.col('true')) # correct predictions \n",
    "            &\n",
    "            (pl.col('pred')==1) # predictions are that EF stay > 40\n",
    "        ).then(True).otherwise(False).alias('true_positive'),\n",
    "    )\n",
    "    \n",
    "    pt_w_tp = df.filter(pl.col('true_positive')).select('empi').unique()['empi'].to_list()\n",
    "    df = df.filter(\n",
    "        ~ pl.col('empi').is_in(pt_w_tp)\n",
    "    ).filter(\n",
    "        pl.col('days_since_diagnosis') < 30\n",
    "    )\n",
    "\n",
    "    repeat_false_positives = []\n",
    "    no_false_positives = []\n",
    "    for group in df.group_by(\"empi\"): \n",
    "        x = group[1].sort(['empi','ecg_date'])\n",
    "        fps = 0\n",
    "        first_ecg_date = None \n",
    "        for row in x.to_dicts(): \n",
    "            if row['false_positive']: \n",
    "                if fps == 0: \n",
    "                    first_ecg_date = row['ecg_date']\n",
    "                fps += 1\n",
    "                repeat_false_positives.append({\n",
    "                    'empi':row['empi'], \n",
    "                    'ecg_date':row['ecg_date'],\n",
    "                    'first_ecg_date':first_ecg_date,\n",
    "                    'fp_count':fps,\n",
    "                })\n",
    "            else: \n",
    "                fps = 0\n",
    "        if fps == 0: # no false positives ever \n",
    "            no_false_positives.append(row['empi'])\n",
    "            \n",
    "\n",
    "    if site['split'] == 'mimic': \n",
    "        lvef = pl.read_csv(\n",
    "            '/storage/shared/mimic/raw/lvef.csv'\n",
    "        ).rename({\n",
    "            'subject_id':'empi',\n",
    "            'study_datetime':'lvef_date',\n",
    "            'result':'lvef'\n",
    "        }).drop(\n",
    "            'measurement'\n",
    "        ).filter(\n",
    "            pl.col('lvef').is_not_null()\n",
    "        ).with_columns(\n",
    "            pl.col('lvef').cast(pl.Int64),\n",
    "            pl.col(\"lvef_date\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S\").dt.date()\n",
    "        ).filter(\n",
    "            (pl.col('lvef')>0) & (pl.col('lvef')<100)\n",
    "        ).sort('lvef_date')\n",
    "    else: \n",
    "        lvef = pl.read_parquet('/storage2/payal/dropbox/private/data/processed/lvef.parquet').sort('lvef_date') \n",
    "\n",
    "    def tmp(df, DAYS): \n",
    "        return df.select(\n",
    "            ['empi','ecg_date']\n",
    "        ).unique(\n",
    "        ).join(\n",
    "            lvef, \n",
    "            on='empi',\n",
    "            how='left'\n",
    "        ).filter(\n",
    "            pl.col('lvef_date') >= pl.col('ecg_date')\n",
    "        ).with_columns(\n",
    "            (pl.col('lvef_date') - pl.col('ecg_date')).dt.total_days().alias('ef_diff')\n",
    "        ).filter(\n",
    "            pl.col('ef_diff') <= DAYS\n",
    "        ).sort(\n",
    "            ['empi', 'lvef']\n",
    "        ).unique(\n",
    "            subset=['empi'], keep='first'\n",
    "        )\n",
    "\n",
    "    DAYS_LIST  = [30, 90, 180, 270, 365, 540, 720]\n",
    "    odds_ratios = []\n",
    "    odds_errors = []\n",
    "    p_values = []\n",
    "    for DAYS in DAYS_LIST:\n",
    "\n",
    "        no = df.filter(\n",
    "            pl.col('empi').is_in(no_false_positives)\n",
    "        ).pipe(tmp, DAYS=DAYS)\n",
    "\n",
    "        rfp = pl.DataFrame(\n",
    "            repeat_false_positives\n",
    "        ).filter(\n",
    "            pl.col('fp_count') > 1\n",
    "        ).pipe(tmp, DAYS=DAYS)\n",
    "\n",
    "        a = rfp.filter(pl.col('lvef')<=40).height\n",
    "        b = rfp.filter(pl.col('lvef')>40).height\n",
    "        c = no.filter(pl.col('lvef')<=40).height\n",
    "        d = no.filter(pl.col('lvef')>40).height\n",
    "\n",
    "        odds_ratio = (a * d) / (b * c)\n",
    "\n",
    "        se_log_or = np.sqrt(1/a + 1/b + 1/c + 1/d)\n",
    "        ci_lower = np.exp(np.log(odds_ratio) - 1.96 * se_log_or)\n",
    "        ci_upper = np.exp(np.log(odds_ratio) + 1.96 * se_log_or)\n",
    "\n",
    "        odds_ratio, p_value = stats.fisher_exact([[a, b], [c, d]])\n",
    "\n",
    "        odds_ratios.append(odds_ratio)\n",
    "        odds_errors.append([odds_ratio-ci_lower, ci_upper-odds_ratio])\n",
    "        p_values.append(p_value)\n",
    "\n",
    "        print(f\"{DAYS} \\t p {p_value:.3f} \\t Odds {odds_ratio:.2f} \\t CI {ci_lower:.2f}–{ci_upper:.2f}\")\n",
    "\n",
    "\n",
    "    fig = barplot([int(x/30) for x in DAYS_LIST], odds_ratios, yerr=np.array(odds_errors).T, decimal=1)\n",
    "    ax = fig.axes[0]  \n",
    "    for bar, p in zip(ax.patches, p_values):\n",
    "        if p < 0.05: \n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, \n",
    "                    ax.get_ylim()[1] * .99,\n",
    "                    '*', \n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')\n",
    "\n",
    "    plt.xlabel('Months')\n",
    "    plt.ylabel('Odds Ratio')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lvef_data(site):\n",
    "    \"\"\"Load and preprocess LVEF data based on site source.\"\"\"\n",
    "    if site['split'] == 'mimic':\n",
    "        lvef = pl.read_csv('/storage/shared/mimic/raw/lvef.csv').rename({\n",
    "            'subject_id': 'empi',\n",
    "            'study_datetime': 'lvef_date',\n",
    "            'result': 'lvef'\n",
    "        }).drop('measurement').filter(\n",
    "            pl.col('lvef').is_not_null()\n",
    "        ).with_columns(\n",
    "            pl.col('lvef').cast(pl.Int64),\n",
    "            pl.col(\"lvef_date\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S\").dt.date()\n",
    "        ).filter((pl.col('lvef') > 0) & (pl.col('lvef') < 100))\n",
    "    else:\n",
    "        lvef = pl.read_parquet('/storage2/payal/dropbox/private/data/processed/lvef.parquet')\n",
    "\n",
    "    return lvef.sort('lvef_date')\n",
    "\n",
    "def plot_trajectory(pt, site):\n",
    "    \"\"\"Plot LVEF trajectory and ECG likelihood with TP/FP/TN/FN labels.\"\"\"\n",
    "    threshold = train_data['all']['sens_to_thres'][0.7]\n",
    "    lvef = load_lvef_data(site)\n",
    "    idx = site['pyd'].data.query('empi == @pt').sort_values('ecg_date').index.values\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Configure LVEF Axis (Left Y-Axis)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax1.set_yticks(range(0, 101, 20))\n",
    "    ax1.tick_params(axis='y', colors='gray')\n",
    "    ax1.spines['left'].set_position(('outward', 10))\n",
    "    ax1.spines['left'].set_color('gray')\n",
    "    ax1.spines['left'].set_linewidth(1)\n",
    "    \n",
    "    # Extract LVEF data for patient\n",
    "    lvef_data = lvef.filter(pl.col('empi') == pt)\n",
    "    lvef_dates = pd.to_datetime(lvef_data['lvef_date'].to_numpy().flatten())\n",
    "    lvef_values = lvef_data['lvef'].to_numpy().flatten()\n",
    "    lvef_colors = ['silver' if val > 40 else 'firebrick' for val in lvef_values]\n",
    "\n",
    "    # Plot LVEF trajectory\n",
    "    ax1.scatter(lvef_dates, lvef_values, c=lvef_colors, marker='o', zorder=2)\n",
    "    for i in range(len(lvef_dates)-1): \n",
    "        ax1.plot(lvef_dates[i:i+2], lvef_values[i:i+2], c=lvef_colors[i+1], zorder=1)  \n",
    "\n",
    "    xlim_dates = lvef_dates\n",
    "    ax1.set_xlim(left=xlim_dates.min().replace(month=1, day=1),\n",
    "                right=xlim_dates.max().replace(month=12, day=31, year=max(xlim_dates).year + 1))\n",
    "    ax1.xaxis.set_major_locator(mdates.YearLocator(1))\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "    ax1.tick_params(axis='x', colors='gray', which='both')\n",
    "    ax1.spines['bottom'].set_color('gray')\n",
    "\n",
    "    ax1.grid(True, axis='x', which='major', linestyle='--', alpha=0.7)\n",
    "    ax1.grid(True, axis='x', which='minor', linestyle=':', alpha=0.5)\n",
    "\n",
    "    # Shared x-axis tick styling\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right', color='gray')\n",
    "    plt.setp(ax1.xaxis.get_minorticklabels(), rotation=45, ha='right', color='gray', fontsize='small')\n",
    "\n",
    "    # Axes styling\n",
    "    ax1.spines['bottom'].set_position(('data', 0))  \n",
    "    ax1.spines['bottom'].set_linewidth(1)\n",
    "\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Configure ECG Likelihood Axis (Right Y-Axis)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylim(0, 1.005)\n",
    "    ax2.set_yticks(np.linspace(0, 1, 11))\n",
    "    ax2.tick_params(axis='y', colors='gray')\n",
    "    ax2.spines['right'].set_position(('outward', 10))\n",
    "    ax2.spines['right'].set_color('gray')\n",
    "    ax2.spines['right'].set_linewidth(1)\n",
    "\n",
    "    # Extract ECG data\n",
    "    dates_ecg = np.array([site['pyd'].data.loc[i, 'ecg_date'].date() for i in idx])\n",
    "    ecg_preds = site['pred'][idx]\n",
    "    ecg_true = site['true'][idx]\n",
    "\n",
    "    # Define labels for TP, FP, TN, FN\n",
    "    texts, colors, labels = [], [], []\n",
    "    for pred, true in zip(ecg_preds, ecg_true):\n",
    "        if pred > threshold and true == 1:\n",
    "            texts.append(r'$\\checkmark$') # TP\n",
    "            colors.append(MY_NAVY)\n",
    "            labels.append('True Positive')\n",
    "        elif pred > threshold and true == 0:\n",
    "            texts.append(r'$\\mathsf{FP}$') # FP\n",
    "            colors.append(MY_NAVY)\n",
    "            labels.append('False Positive')\n",
    "        elif pred <= threshold and true == 0:\n",
    "            texts.append(r'$\\times$' ) # TN\n",
    "            colors.append('silver')\n",
    "            labels.append('True Negative')\n",
    "        else:\n",
    "            texts.append(r'$\\mathsf{FN}$') \n",
    "            colors.append('silver')\n",
    "            labels.append('False Negative')\n",
    "\n",
    "    # Plot ECG predictions with TP/FP/TN/FN labels\n",
    "    for date, pred, text, color, label in zip(dates_ecg, ecg_preds, texts, colors, labels):\n",
    "        ax2.text(date, pred, text, fontsize=10, ha='center', va='bottom', color=color, label=label)\n",
    "    \n",
    "    # Configure X-Axis\n",
    "    ax1.set_xlim(left=lvef_dates.min().replace(month=1, day=1),\n",
    "                 right=lvef_dates.max().replace(month=12, day=31, year=lvef_dates.max().year ))\n",
    "    ax1.xaxis.set_major_locator(mdates.YearLocator(1))\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax1.tick_params(axis='x', colors='gray', rotation=45)\n",
    "\n",
    "    # LVEF threshold line\n",
    "    ax1.axhline(y=40, color='firebrick', linestyle='--')\n",
    "    ax1.text(pd.Timestamp(lvef_dates.min().replace(month=3, day=1)), 40+1, \"40% LVEF\", color='firebrick', fontsize=10, va='bottom', ha='left')\n",
    "\n",
    "    # ECG threshold line\n",
    "    ax2.axhline(y=threshold,  color=MY_NAVY, linestyle='--')\n",
    "    ax2.text(pd.Timestamp(lvef_dates.max().replace(month=9, day=30, year=lvef_dates.max().year -1  )), \n",
    "             threshold+0.01, \"70% Sensitivity\", color=MY_NAVY, fontsize=10, va='bottom', ha='left')\n",
    "\n",
    "    ax2.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "\n",
    "    # Align ticks on both axes\n",
    "    ax1.tick_params(axis='y', direction='in', pad=5)\n",
    "    ax2.tick_params(axis='y', direction='in', pad=5)\n",
    "\n",
    "    # Hide unnecessary spines\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "    ax1.set_ylabel('LVEF', color='gray', labelpad=-5)\n",
    "    ax2.set_ylabel('Probability of Worsening LVEF for ECG', color='gray', rotation=270, labelpad=5, va='bottom')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in [100223049,100202452,101091462, 103200474, 105812520, 100358399, 100615898, 101137610, 103401384]: \n",
    "    plot_trajectory(pt, sites[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single lead model comparisons\n",
    "auc_mean = pl.read_csv('/storage2/payal/Dropbox (Partners HealthCare)/private/SILVER/src/auc.csv')\n",
    "auc_upper = pl.read_csv('/storage2/payal/Dropbox (Partners HealthCare)/private/SILVER/src/auc_upper.csv')\n",
    "auc_lower = pl.read_csv('/storage2/payal/Dropbox (Partners HealthCare)/private/SILVER/src/auc_lower.csv')\n",
    "\n",
    "cols = [x for x in auc_mean.columns if 'AUROC' in x]\n",
    "cols = [x for x in cols if not x.endswith('MIN') and not x.endswith('MAX')]\n",
    "auc_mean = auc_mean.select(cols)\n",
    "\n",
    "cols = [x for x in auc_upper.columns if 'AUROC' in x]\n",
    "cols = [x for x in cols if not x.endswith('MIN') and not x.endswith('MAX')]\n",
    "auc_upper = auc_upper.select(cols)\n",
    "\n",
    "cols = [x for x in auc_lower.columns if 'AUROC' in x]\n",
    "cols = [x for x in cols if not x.endswith('MIN') and not x.endswith('MAX')]\n",
    "auc_lower = auc_lower.select(cols)\n",
    "\n",
    "df = pl.concat([auc_mean,auc_lower,auc_upper], how='horizontal')\n",
    "df = df.with_columns([pl.when(pl.col(col) == \"\").then(None).otherwise(pl.col(col)).alias(col) for col in df.columns])\n",
    "df = df.with_columns([pl.col(col).cast(pl.Float64).alias(col) for col in df.columns])\n",
    "df = df.rename({col: '_'.join([col.split('_')[0],col.split('_')[-1]]) for col in df.columns})\n",
    "df = df.select([pl.col(col).drop_nulls().first().alias(col) for col in df.columns])\n",
    "df = df.to_pandas()\n",
    "\n",
    "lead_names = [col.replace(\"_mean\", \"\") for col in df.columns if \"_mean\" in col]\n",
    "means = df[[col for col in df.columns if \"_mean\" in col]].values.flatten()\n",
    "lower = df[[col for col in df.columns if \"_lower\" in col]].values.flatten()\n",
    "upper = df[[col for col in df.columns if \"_upper\" in col]].values.flatten()\n",
    "errors = np.abs(np.array([*zip((lower-means),(upper-means))]))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.errorbar(\n",
    "    lead_names,\n",
    "    means,\n",
    "    yerr=errors.T,\n",
    "    label=f\"Sensitivity {sens}%\",\n",
    "    capsize=3,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    linestyle=\"\",\n",
    "    linewidth=1,\n",
    "    color=MY_NAVY,\n",
    ")\n",
    "plt.gca().set_xlabel(\"Single Lead\", fontsize=12, color='gray')\n",
    "plt.gca().set_ylabel(\"AUROC\", fontsize=12, color='gray')\n",
    "plt.gca().tick_params(axis='y', colors='gray')\n",
    "plt.gca().spines['left'].set_color('gray')\n",
    "plt.gca().spines['left'].set_linewidth(1)\n",
    "plt.gca().tick_params(axis='x', colors='gray', which='both')\n",
    "plt.gca().spines['bottom'].set_color('gray')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(.75,1)\n",
    "plt.gca().axhline(y=.926,  color=MY_NAVY, linestyle='--')\n",
    "plt.grid(True)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
