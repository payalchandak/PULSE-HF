{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T17:30:02.027188Z",
     "start_time": "2025-01-19T17:29:59.408942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandak/miniconda3/envs/ecg/lib/python3.8/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import lightning as L\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, roc_curve\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import hydra\n",
    "import wandb\n",
    "from dataset import SupervisedDataset\n",
    "from lightning_modules import SupervisedTask\n",
    "from models.ecg_models import *\n",
    "from run import interpolate\n",
    "from torchview import draw_graph\n",
    "import cairosvg\n",
    "from bs4 import BeautifulSoup\n",
    "import torch.nn as nn\n",
    "pl.Config.set_tbl_rows(50)\n",
    "MY_NAVY = '#001F54'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_RUN='payalchandak/SILVER/nuzrc47q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 140799\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:2'\n",
    "cfg = OmegaConf.create(wandb.Api().run(WANDB_RUN).config)\n",
    "L.seed_everything(cfg.utils.seed)\n",
    "train_pyd = hydra.utils.instantiate(cfg.dataset, split='train')\n",
    "cfg = interpolate(cfg, train_pyd)\n",
    "del train_pyd\n",
    "trainer = L.Trainer(devices=[int(device[-1])])\n",
    "LM = SupervisedTask.load_from_checkpoint(cfg.best_model_path, map_location=torch.device(device))\n",
    "model = LM.model\n",
    "model.to(device)\n",
    "model.eval()\n",
    "cfg.optimizer.batch_size = 2048\n",
    "cfg.dataset.config.label = 'future_1_365_any_below_40'\n",
    "pyd = hydra.utils.instantiate(cfg.dataset, split='test')\n",
    "pyd.data = pyd.data.reset_index(drop=1)\n",
    "assert len(pyd)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset = pyd,\n",
    "    batch_size = cfg.optimizer.batch_size,\n",
    "    num_workers = 0, \n",
    "    collate_fn = pyd.collate,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "for batch in loader: \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture \n",
    "\n",
    "class ECGEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "graph = draw_graph(\n",
    "    ECGEncoder(model.ecg_encoder, model.ecg_decoder),\n",
    "    input_data=batch['ecg'][0].unsqueeze(0),\n",
    "    graph_dir=\"TB\",                # top-to-bottom layout\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"ecg_encoder\",\n",
    "    roll=True,\n",
    "    depth=4,\n",
    "    show_shapes=True,\n",
    "    hide_module_functions=False   # we want to manually clean depth text\n",
    ")\n",
    "\n",
    "graph.visual_graph.render(format=\"svg\", filename=\"ecg_encoder\", cleanup=True)\n",
    "\n",
    "with open(\"ecg_encoder.svg\", \"r\") as f:\n",
    "    svg = f.read()\n",
    "soup = BeautifulSoup(svg, \"xml\")\n",
    "for text in soup.find_all(\"text\"):\n",
    "    if text.string:\n",
    "        s = text.string.strip()\n",
    "        if s.startswith(\"depth:\"):\n",
    "            text.decompose()  # delete the depth line entirely\n",
    "        elif s == \"input-tensor\":\n",
    "            text.string.replace_with(\"12-lead ECG\")\n",
    "        elif s == \"output-tensor\":\n",
    "            text.string.replace_with(\"ECG embed\")\n",
    "with open(\"ecg_encoder.svg\", \"w\") as f:\n",
    "    f.write(str(soup))\n",
    "cairosvg.svg2png(url=\"ecg_encoder.svg\",write_to=\"ecg_encoder.png\",dpi=300)\n",
    "\n",
    "graph = draw_graph(\n",
    "    ECGEncoder(model.ecg_encoder, model.ecg_decoder),\n",
    "    input_data=batch['ecg'][0].unsqueeze(0),\n",
    "    graph_dir=\"TB\",                # top-to-bottom layout\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"ecg_encoder_summary\",\n",
    "    roll=True,\n",
    "    depth=1,\n",
    "    show_shapes=True,\n",
    "    hide_module_functions=False   # we want to manually clean depth text\n",
    ")\n",
    "\n",
    "graph.visual_graph.render(format=\"svg\", filename=\"ecg_encoder_summary\", cleanup=True)\n",
    "\n",
    "with open(\"ecg_encoder_summary.svg\", \"r\") as f:\n",
    "    svg = f.read()\n",
    "soup = BeautifulSoup(svg, \"xml\")\n",
    "for text in soup.find_all(\"text\"):\n",
    "    if text.string:\n",
    "        s = text.string.strip()\n",
    "        if s.startswith(\"depth:\"):\n",
    "            text.decompose()  # delete the depth line entirely\n",
    "        elif s == \"input-tensor\":\n",
    "            text.string.replace_with(\"12-lead ECG\")\n",
    "        elif s == \"output-tensor\":\n",
    "            text.string.replace_with(\"ECG embed\")\n",
    "with open(\"ecg_encoder_summary.svg\", \"w\") as f:\n",
    "    f.write(str(soup))\n",
    "cairosvg.svg2png(url=\"ecg_encoder_summary.svg\",write_to=\"ecg_encoder_summary.png\",dpi=300)\n",
    "\n",
    "\n",
    "graph = draw_graph(\n",
    "    model.prior_lvef_decoder,\n",
    "    input_data=torch.randn(1,15),\n",
    "    graph_dir=\"TB\",                # top-to-bottom layout\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"lvef_encoder\",\n",
    "    roll=True,\n",
    "    show_shapes=True,\n",
    "    hide_module_functions=False   # we want to manually clean depth text\n",
    ")\n",
    "\n",
    "graph.visual_graph.render(format=\"svg\", filename=\"lvef_encoder\", cleanup=True)\n",
    "\n",
    "with open(\"lvef_encoder.svg\", \"r\") as f:\n",
    "    svg = f.read()\n",
    "soup = BeautifulSoup(svg, \"xml\")\n",
    "for text in soup.find_all(\"text\"):\n",
    "    if text.string:\n",
    "        s = text.string.strip()\n",
    "        if s.startswith(\"depth:\"):\n",
    "            text.decompose()  # delete the depth line entirely\n",
    "        elif s == \"input-tensor\":\n",
    "            text.string.replace_with(\"LVEF history\")\n",
    "        elif s == \"output-tensor\":\n",
    "            text.string.replace_with(\"LVEF embed\")\n",
    "with open(\"lvef_encoder.svg\", \"w\") as f:\n",
    "    f.write(str(soup))\n",
    "cairosvg.svg2png(url=\"lvef_encoder.svg\",write_to=\"lvef_encoder.png\",dpi=300)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, mlp):\n",
    "        super().__init__()\n",
    "        self.mlp = mlp\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.mlp(x+y)\n",
    "\n",
    "\n",
    "graph = draw_graph(\n",
    "    Decoder(model.mlp),\n",
    "    input_data=(torch.randn(1,512),torch.randn(1,512)),\n",
    "    graph_dir=\"TB\",                # top-to-bottom layout\n",
    "    expand_nested=True,\n",
    "    save_graph=True,\n",
    "    filename=\"decoder\",\n",
    "    roll=True,\n",
    "    show_shapes=True,\n",
    "    hide_module_functions=False   # we want to manually clean depth text\n",
    ")\n",
    "\n",
    "graph.visual_graph.render(format=\"svg\", filename=\"decoder\", cleanup=True)\n",
    "\n",
    "with open(\"decoder.svg\", \"r\") as f:\n",
    "    svg = f.read()\n",
    "soup = BeautifulSoup(svg, \"xml\")\n",
    "input_count = 0\n",
    "for text in soup.find_all(\"text\"):\n",
    "    if text.string:\n",
    "        s = text.string.strip()\n",
    "        if s.startswith(\"depth:\"):\n",
    "            text.decompose()\n",
    "        elif s == \"input-tensor\":\n",
    "            if input_count == 0:\n",
    "                text.string.replace_with(\"ECG embed\")\n",
    "            elif input_count == 1:\n",
    "                text.string.replace_with(\"LVEF embed\")\n",
    "            input_count += 1\n",
    "        elif s == \"output-tensor\":\n",
    "            text.string.replace_with(\"Prediction\")\n",
    "with open(\"decoder.svg\", \"w\") as f:\n",
    "    f.write(str(soup))\n",
    "cairosvg.svg2png(url=\"decoder.svg\",write_to=\"decoder.png\",dpi=300)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Delete all SVG files in current directory\n",
    "for file in Path(\".\").glob(\"*.svg\"):\n",
    "    file.unlink()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
